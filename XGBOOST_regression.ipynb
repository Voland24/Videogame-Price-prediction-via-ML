{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63132224-6e84-40d4-9b8a-3d279155b301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 34\n",
      "max_resources_: 2819\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 34\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 102\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 18\n",
      "n_resources: 306\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 918\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 2754\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters: {'regressor__booster': 'gbtree', 'regressor__colsample_bytree': 0.7, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_split_loss': 0, 'regressor__n_estimators': 100, 'regressor__reg_alpha': 0.5, 'regressor__reg_lambda': 1, 'regressor__subsample': 1}\n",
      "Lowest RMSE:  0.7215463999585464\n",
      "Score 0.7389508234702605\n"
     ]
    }
   ],
   "source": [
    "# XGBoost regressor - halvinggridsearch\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "data = pd.read_json('./content/video_games_newer_all_data_with_rawg_final_for_train_v2.json')\n",
    "data = data[data.NA_Sales <= 6]\n",
    "data = data.drop(columns=['Year_of_Release', 'User_Score'])\n",
    "\n",
    "training, test = train_test_split(data, test_size = 0.25)\n",
    "\n",
    "features = training.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis = 1).columns\n",
    "\n",
    "training_features, training_labels = training[features], training['NA_Sales']\n",
    "test_features, test_labels = test[features], test['NA_Sales']\n",
    "\n",
    "params = { 'regressor__booster': ['gbtree'],\n",
    "            'regressor__max_depth': [3, 6, 10],\n",
    "           'regressor__learning_rate': [0.01, 0.005, 0.015],\n",
    "           'regressor__n_estimators': [100, 500, 1000],\n",
    "          'regressor__subsample': [0.5, 1],\n",
    "           'regressor__colsample_bytree': [0.1, 0.3, 0.7],\n",
    "           'regressor__reg_alpha': [0.5],\n",
    "           'regressor__reg_lambda': [1],\n",
    "           'regressor__min_split_loss': [0]\n",
    "         }\n",
    "\n",
    "xgb_pipeline = Pipeline([('regressor', XGBRegressor())])\n",
    "clf = HalvingGridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=params,               \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(training_features, training_labels)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "neg_mse = clf.score(test_features, test_labels)\n",
    "print(f'Score {(-neg_mse)**(1/2.0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74fbcb4-a0d4-435f-9f51-7ad5bfdcda41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 34\n",
      "max_resources_: 2754\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 34\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 102\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 18\n",
      "n_resources: 306\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 918\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 2754\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters: {'regressor__booster': 'gbtree', 'regressor__colsample_bytree': 0.3, 'regressor__learning_rate': 0.005, 'regressor__max_depth': 10, 'regressor__min_split_loss': 0, 'regressor__n_estimators': 500, 'regressor__reg_alpha': 0.5, 'regressor__reg_lambda': 1, 'regressor__subsample': 1}\n",
      "Lowest RMSE:  0.3230350767559744\n",
      "Score 0.3344123988036222\n"
     ]
    }
   ],
   "source": [
    "# XGBoost regressor - halvinggridsearch\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "data = pd.read_json('./content/video_games_newer_all_data_with_rawg_final_for_train_v2.json')\n",
    "data = data[data.EU_Sales <= 2]\n",
    "data = data.drop(columns=['Year_of_Release', 'User_Score'])\n",
    "\n",
    "training, test = train_test_split(data, test_size = 0.25)\n",
    "\n",
    "features = training.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis = 1).columns\n",
    "\n",
    "training_features, training_labels = training[features], training['EU_Sales']\n",
    "test_features, test_labels = test[features], test['EU_Sales']\n",
    "\n",
    "params = { 'regressor__booster': ['gbtree'],\n",
    "            'regressor__max_depth': [3, 6, 10],\n",
    "           'regressor__learning_rate': [0.01, 0.005, 0.015],\n",
    "           'regressor__n_estimators': [100, 500, 1000],\n",
    "          'regressor__subsample': [0.5, 1],\n",
    "           'regressor__colsample_bytree': [0.1, 0.3, 0.7],\n",
    "           'regressor__reg_alpha': [0.5],\n",
    "           'regressor__reg_lambda': [1],\n",
    "           'regressor__min_split_loss': [0]\n",
    "         }\n",
    "\n",
    "xgb_pipeline = Pipeline([('regressor', XGBRegressor())])\n",
    "clf = HalvingGridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=params,               \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(training_features, training_labels)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "neg_mse = clf.score(test_features, test_labels)\n",
    "print(f'Score {(-neg_mse)**(1/2.0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36dabdf-9cd3-43b3-8d0b-693a100eae87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 34\n",
      "max_resources_: 2757\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 34\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 102\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 18\n",
      "n_resources: 306\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 918\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 2754\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters: {'regressor__booster': 'gbtree', 'regressor__colsample_bytree': 0.1, 'regressor__learning_rate': 0.015, 'regressor__max_depth': 3, 'regressor__min_split_loss': 0, 'regressor__n_estimators': 1000, 'regressor__reg_alpha': 0.5, 'regressor__reg_lambda': 1, 'regressor__subsample': 0.5}\n",
      "Lowest RMSE:  0.10298011058422847\n",
      "Score 0.10226160944746285\n"
     ]
    }
   ],
   "source": [
    "# XGBoost regressor - halvinggridsearch\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "data = pd.read_json('./content/video_games_newer_all_data_with_rawg_final_for_train_v2.json')\n",
    "data = data[data.JP_Sales <= 0.7]\n",
    "data = data.drop(columns=['Year_of_Release', 'User_Score'])\n",
    "\n",
    "training, test = train_test_split(data, test_size = 0.25)\n",
    "\n",
    "features = training.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis = 1).columns\n",
    "\n",
    "training_features, training_labels = training[features], training['JP_Sales']\n",
    "test_features, test_labels = test[features], test['JP_Sales']\n",
    "\n",
    "params = { 'regressor__booster': ['gbtree'],\n",
    "            'regressor__max_depth': [3, 6, 10],\n",
    "           'regressor__learning_rate': [0.01, 0.005, 0.015],\n",
    "           'regressor__n_estimators': [100, 500, 1000],\n",
    "          'regressor__subsample': [0.5, 1],\n",
    "           'regressor__colsample_bytree': [0.1, 0.3, 0.7],\n",
    "           'regressor__reg_alpha': [0.5],\n",
    "           'regressor__reg_lambda': [1],\n",
    "           'regressor__min_split_loss': [0]\n",
    "         }\n",
    "\n",
    "xgb_pipeline = Pipeline([('regressor', XGBRegressor())])\n",
    "clf = HalvingGridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=params,               \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(training_features, training_labels)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "neg_mse = clf.score(test_features, test_labels)\n",
    "print(f'Score {(-neg_mse)**(1/2.0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c893c76-2406-4ddb-9c8f-c5633c1692c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 34\n",
      "max_resources_: 2829\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 34\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 102\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 18\n",
      "n_resources: 306\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 918\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 2754\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters: {'regressor__booster': 'gbtree', 'regressor__colsample_bytree': 0.3, 'regressor__learning_rate': 0.015, 'regressor__max_depth': 10, 'regressor__min_split_loss': 0, 'regressor__n_estimators': 500, 'regressor__reg_alpha': 0.5, 'regressor__reg_lambda': 1, 'regressor__subsample': 0.5}\n",
      "Lowest RMSE:  0.17186755235511636\n",
      "Score 0.17671789337264557\n"
     ]
    }
   ],
   "source": [
    "# XGBoost regressor - halvinggridsearch\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "data = pd.read_json('./content/video_games_newer_all_data_with_rawg_final_for_train_v2.json')\n",
    "data = data[data.Other_Sales <= 2]\n",
    "data = data.drop(columns=['Year_of_Release', 'User_Score'])\n",
    "\n",
    "training, test = train_test_split(data, test_size = 0.25)\n",
    "\n",
    "features = training.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis = 1).columns\n",
    "\n",
    "training_features, training_labels = training[features], training['Other_Sales']\n",
    "test_features, test_labels = test[features], test['Other_Sales']\n",
    "\n",
    "params = { 'regressor__booster': ['gbtree'],\n",
    "            'regressor__max_depth': [3, 6, 10],\n",
    "           'regressor__learning_rate': [0.01, 0.005, 0.015],\n",
    "           'regressor__n_estimators': [100, 500, 1000],\n",
    "          'regressor__subsample': [0.5, 1],\n",
    "           'regressor__colsample_bytree': [0.1, 0.3, 0.7],\n",
    "           'regressor__reg_alpha': [0.5],\n",
    "           'regressor__reg_lambda': [1],\n",
    "           'regressor__min_split_loss': [0]\n",
    "         }\n",
    "\n",
    "xgb_pipeline = Pipeline([('regressor', XGBRegressor())])\n",
    "clf = HalvingGridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=params,               \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(training_features, training_labels)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "neg_mse = clf.score(test_features, test_labels)\n",
    "print(f'Score {(-neg_mse)**(1/2.0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46faa299-8b92-43ba-9352-d2cc98661af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 33\n",
      "max_resources_: 2743\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 33\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 99\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 18\n",
      "n_resources: 297\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 891\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 2673\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters: {'regressor__booster': 'gbtree', 'regressor__colsample_bytree': 0.3, 'regressor__learning_rate': 0.005, 'regressor__max_depth': 6, 'regressor__min_split_loss': 0, 'regressor__n_estimators': 500, 'regressor__reg_alpha': 0.5, 'regressor__reg_lambda': 1, 'regressor__subsample': 0.5}\n",
      "Lowest RMSE:  0.9586986827087639\n",
      "Score 1.0067450371424271\n"
     ]
    }
   ],
   "source": [
    "# XGBoost regressor - halvinggridsearch\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "data = pd.read_json('./content/video_games_newer_all_data_with_rawg_final_for_train_v2.json')\n",
    "data = data[data.Global_Sales <= 6]\n",
    "data = data.drop(columns=['Year_of_Release', 'User_Score'])\n",
    "\n",
    "training, test = train_test_split(data, test_size = 0.25)\n",
    "\n",
    "features = training.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis = 1).columns\n",
    "\n",
    "training_features, training_labels = training[features], training['Global_Sales']\n",
    "test_features, test_labels = test[features], test['Global_Sales']\n",
    "\n",
    "params = { 'regressor__booster': ['gbtree'],\n",
    "            'regressor__max_depth': [3, 6, 10],\n",
    "           'regressor__learning_rate': [0.01, 0.005, 0.015],\n",
    "           'regressor__n_estimators': [100, 500, 1000],\n",
    "          'regressor__subsample': [0.5, 1],\n",
    "           'regressor__colsample_bytree': [0.1, 0.3, 0.7],\n",
    "           'regressor__reg_alpha': [0.5],\n",
    "           'regressor__reg_lambda': [1],\n",
    "           'regressor__min_split_loss': [0]\n",
    "         }\n",
    "\n",
    "xgb_pipeline = Pipeline([('regressor', XGBRegressor())])\n",
    "clf = HalvingGridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=params,               \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(training_features, training_labels)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "neg_mse = clf.score(test_features, test_labels)\n",
    "print(f'Score {(-neg_mse)**(1/2.0)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
