{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "vaVSNjN6GYjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE TO READ THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_all = pd.read_json('/content/video_games_newer_all_data_with_rawg_final_for_train.json')\n",
        "\n",
        "df_all.head(2)\n",
        "\n",
        "print(df_all.loc[:5,'Year_of_Release' : 'reviews_count'])"
      ],
      "metadata": {
        "id": "zfnoR_GBG6h4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cf0697-c570-4336-ccb3-480cec69551d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year_of_Release  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \\\n",
            "0             2002      0.49      0.38      0.26         0.13          1.27   \n",
            "1             2002      0.23      0.18      0.20         0.06          0.68   \n",
            "2             2002      0.14      0.11      0.17         0.04          0.46   \n",
            "3             2000      0.51      0.35      0.00         0.06          0.92   \n",
            "4             2008      0.08      0.00      0.00         0.01          0.08   \n",
            "5             2008      0.12      0.52      0.00         0.02          0.66   \n",
            "\n",
            "   User_Score  added  screenshots_count  achievements_count  reddit_count  \\\n",
            "0         8.5     35                 18                   0             0   \n",
            "1         8.9     18                 29                   0             0   \n",
            "2         8.7     17                 20                   0             0   \n",
            "3         6.7     97                  9                   0             0   \n",
            "4         3.2      1                  0                   0             0   \n",
            "5         6.0      5                  4                   0             0   \n",
            "\n",
            "   twitch_count  youtube_count  ratings_count  suggestions_count  \\\n",
            "0             0              0             12                547   \n",
            "1             0              0              4                446   \n",
            "2             0              0              4                529   \n",
            "3             0              0             33                361   \n",
            "4             0              0              0                  0   \n",
            "5             0              0              0                 61   \n",
            "\n",
            "   additions_count  game_series_count  reviews_count  \n",
            "0                0                  8             12  \n",
            "1                0                  8              4  \n",
            "2                0                  8              4  \n",
            "3                0                 22             33  \n",
            "4                0                  0              0  \n",
            "5                0                  0              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STANDARDIZE THE DATA\n",
        "\n",
        "df_all[['Year_of_Release','added', 'screenshots_count', \n",
        "     'achievements_count',\t'reddit_count',\t'twitch_count',\t'youtube_count',\n",
        "     'ratings_count',\t'suggestions_count',\t'additions_count',\n",
        "     'game_series_count',\t'reviews_count', 'User_Score']] = StandardScaler().fit_transform(df_all[['Year_of_Release','added', 'screenshots_count', \n",
        "     'achievements_count',\t'reddit_count',\t'twitch_count',\t'youtube_count',\n",
        "     'ratings_count',\t'suggestions_count',\t'additions_count',\n",
        "     'game_series_count',\t'reviews_count', 'User_Score']])"
      ],
      "metadata": {
        "id": "he1Bg0zvWWKt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_all.loc[:5,'NA_Sales' : 'reviews_count'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlEtMNn-Wh39",
        "outputId": "09e0e598-bc1b-4c68-a848-e2653a9af728"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  User_Score  \\\n",
            "0      0.49      0.38      0.26         0.13          1.27    0.896010   \n",
            "1      0.23      0.18      0.20         0.06          0.68    1.180726   \n",
            "2      0.14      0.11      0.17         0.04          0.46    1.038368   \n",
            "3      0.51      0.35      0.00         0.06          0.92   -0.385213   \n",
            "4      0.08      0.00      0.00         0.01          0.08   -2.876479   \n",
            "5      0.12      0.52      0.00         0.02          0.66   -0.883466   \n",
            "\n",
            "      added  screenshots_count  achievements_count  reddit_count  \\\n",
            "0 -0.343627          -0.239689           -0.398182     -0.173897   \n",
            "1 -0.354023          -0.026918           -0.398182     -0.173897   \n",
            "2 -0.354634          -0.201003           -0.398182     -0.173897   \n",
            "3 -0.305712          -0.413774           -0.398182     -0.173897   \n",
            "4 -0.364419          -0.587858           -0.398182     -0.173897   \n",
            "5 -0.361972          -0.510487           -0.398182     -0.173897   \n",
            "\n",
            "   twitch_count  youtube_count  ratings_count  suggestions_count  \\\n",
            "0     -0.666494      -0.598946      -0.295154           1.048865   \n",
            "1     -0.666494      -0.598946      -0.315502           0.533928   \n",
            "2     -0.666494      -0.598946      -0.315502           0.957094   \n",
            "3     -0.666494      -0.598946      -0.241739           0.100565   \n",
            "4     -0.666494      -0.598946      -0.325677          -1.739952   \n",
            "5     -0.666494      -0.598946      -0.325677          -1.428951   \n",
            "\n",
            "   additions_count  game_series_count  reviews_count  \n",
            "0        -0.228493           0.345508      -0.295242  \n",
            "1        -0.228493           0.345508      -0.315419  \n",
            "2        -0.228493           0.345508      -0.315419  \n",
            "3        -0.228493           1.926687      -0.242277  \n",
            "4        -0.228493          -0.558023      -0.325508  \n",
            "5        -0.228493          -0.558023      -0.325508  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#potential columns to drop\n",
        "\n",
        "#df_all = df_all.drop(columns = ['Year_of_Release', 'screenshots_count', 'additions_count', 'game_series_count'])"
      ],
      "metadata": {
        "id": "zGdLrA3jWc-F"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPARE FOR REGRESSION\n",
        "\n",
        "training, test = train_test_split(df_all, test_size = 0.25, random_state = 32)\n",
        "features = training.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis = 1).columns\n",
        "\n",
        "training_features, training_labels = training[features], training['NA_Sales']\n",
        "test_features, test_labels = test[features], test['NA_Sales']\n",
        "\n",
        "pipeline = Pipeline([('regressor', MLPRegressor())])\n",
        "#pipeline.fit(training_features, training_labels)\n"
      ],
      "metadata": {
        "id": "3mvK6RTdzofR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iSUNPXJIFOY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb85ee85-05f8-4384-b427-77095721191b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 105\n",
            "max_resources_: 2851\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 36\n",
            "n_resources: 105\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 12\n",
            "n_resources: 315\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 4\n",
            "n_resources: 945\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 2835\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "{'regressor__activation': 'logistic', 'regressor__alpha': 0.05, 'regressor__hidden_layer_sizes': (50, 100, 50), 'regressor__learning_rate': 'constant', 'regressor__solver': 'adam'}\n",
            "Best score: -1.771747835052618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#MLP REGRESSION WITH HALVING GRID SEARCH\n",
        "\n",
        "\n",
        "estimator=pipeline\n",
        "\n",
        "\n",
        "param_grid = {'regressor__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,1)],\n",
        "          'regressor__activation': ['relu','tanh','logistic'],\n",
        "          'regressor__alpha': [0.0001, 0.05],\n",
        "          'regressor__learning_rate': ['constant','adaptive'],\n",
        "          'regressor__solver': ['adam']}\n",
        "\n",
        "gsc = HalvingGridSearchCV(\n",
        "    estimator,\n",
        "    param_grid,\n",
        "    cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "\n",
        "grid_result = gsc.fit(training_features, training_labels)\n",
        "\n",
        "\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "print(best_params)\n",
        "\n",
        "print(f'Best score: {grid_result.best_score_}')\n",
        "\n",
        "# best_mlp = MLPRegressor(hidden_layer_sizes = best_params[\"hidden_layer_sizes\"], \n",
        "#                         activation =best_params[\"activation\"],\n",
        "#                         solver=best_params[\"solver\"],\n",
        "#                         max_iter= 5000, n_iter_no_change = 200\n",
        "#               )\n",
        "\n",
        "# scoring = {\n",
        "#            'abs_error': 'neg_mean_absolute_error',\n",
        "#            'squared_error': 'neg_mean_squared_error',\n",
        "#            'r2':'r2'}\n",
        "\n",
        "# scores = cross_val_score(best_mlp, training_features, training_labels, cv=10, scoring=scoring)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_all = pd.read_json('/content/video_games_newer_all_data_with_rawg_final_for_train.json')\n",
        "\n",
        "df_all.head(2)\n",
        "\n",
        "print(df_all.loc[:5,'Year_of_Release' : 'reviews_count'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSkJEMkGYGxr",
        "outputId": "e058f8e2-f910-4ad6-9087-53c682bc50b0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year_of_Release  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \\\n",
            "0             2002      0.49      0.38      0.26         0.13          1.27   \n",
            "1             2002      0.23      0.18      0.20         0.06          0.68   \n",
            "2             2002      0.14      0.11      0.17         0.04          0.46   \n",
            "3             2000      0.51      0.35      0.00         0.06          0.92   \n",
            "4             2008      0.08      0.00      0.00         0.01          0.08   \n",
            "5             2008      0.12      0.52      0.00         0.02          0.66   \n",
            "\n",
            "   User_Score  added  screenshots_count  achievements_count  reddit_count  \\\n",
            "0         8.5     35                 18                   0             0   \n",
            "1         8.9     18                 29                   0             0   \n",
            "2         8.7     17                 20                   0             0   \n",
            "3         6.7     97                  9                   0             0   \n",
            "4         3.2      1                  0                   0             0   \n",
            "5         6.0      5                  4                   0             0   \n",
            "\n",
            "   twitch_count  youtube_count  ratings_count  suggestions_count  \\\n",
            "0             0              0             12                547   \n",
            "1             0              0              4                446   \n",
            "2             0              0              4                529   \n",
            "3             0              0             33                361   \n",
            "4             0              0              0                  0   \n",
            "5             0              0              0                 61   \n",
            "\n",
            "   additions_count  game_series_count  reviews_count  \n",
            "0                0                  8             12  \n",
            "1                0                  8              4  \n",
            "2                0                  8              4  \n",
            "3                0                 22             33  \n",
            "4                0                  0              0  \n",
            "5                0                  0              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPARE DATA FOR CLASSIFICATION\n",
        "import numpy as np\n",
        "\n",
        "tmp = df_all\n",
        "tmp['User_Score'] = np.where(tmp['User_Score'] < 6.0, 0, tmp['User_Score'])\n",
        "tmp['User_Score'] = np.where((6.0 <= tmp['User_Score']) & ( tmp['User_Score'] < 7.0), 1 ,tmp['User_Score'])\n",
        "tmp['User_Score'] = np.where((7.0 <= tmp['User_Score']) & ( tmp['User_Score'] < 7.5), 2 ,tmp['User_Score'])\n",
        "tmp['User_Score'] = np.where((7.5 <= tmp['User_Score']) & ( tmp['User_Score'] < 8.0), 3 ,tmp['User_Score'])\n",
        "tmp['User_Score'] = np.where((8.0 <= tmp['User_Score']) & ( tmp['User_Score'] < 8.5), 4 ,tmp['User_Score'])\n",
        "tmp['User_Score'] = np.where(8.5 <= tmp['User_Score'] , 5 ,tmp['User_Score'])\n",
        "tmp['User_Score'] = tmp['User_Score'].astype('category').cat.codes\n"
      ],
      "metadata": {
        "id": "AezYzb7D2-Bs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all[['Year_of_Release','added', 'screenshots_count', \n",
        "     'achievements_count',\t'reddit_count',\t'twitch_count',\t'youtube_count',\n",
        "     'ratings_count',\t'suggestions_count',\t'additions_count',\n",
        "     'game_series_count',\t'reviews_count']] = StandardScaler().fit_transform(df_all[['Year_of_Release','added', 'screenshots_count', \n",
        "     'achievements_count',\t'reddit_count',\t'twitch_count',\t'youtube_count',\n",
        "     'ratings_count',\t'suggestions_count',\t'additions_count',\n",
        "     'game_series_count',\t'reviews_count']])"
      ],
      "metadata": {
        "id": "ylhmwMgYYR6q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training, test = train_test_split(tmp, test_size = 0.25, random_state = 32)\n",
        "features = training.drop(['User_Score'], axis = 1).columns\n",
        "\n",
        "training_features, training_labels = training[features], training['User_Score']\n",
        "test_features, test_labels = test[features], test['User_Score']\n",
        "\n",
        "\n",
        "pipeline = Pipeline([('classifier', MLPClassifier(max_iter=100))])"
      ],
      "metadata": {
        "id": "b9KjDVvQYVS8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP CLASSIFICATION WITH HALVING GRID SEARCH\n",
        "\n",
        "mlp_gs = pipeline\n",
        "parameter_space = {\n",
        "    'classifier__hidden_layer_sizes': [(10,30,10),(20,)],\n",
        "    'classifier__activation': ['tanh', 'relu'],\n",
        "    'classifier__solver': ['sgd', 'adam'],\n",
        "    'classifier__alpha': [0.0001, 0.05],\n",
        "    'classifier__learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "\n",
        "clf = HalvingGridSearchCV(mlp_gs, parameter_space, verbose=1, n_jobs=-1, cv=5, scoring='f1_macro')\n",
        "\n",
        "grid_result = clf.fit(training_features, training_labels)\n",
        "\n",
        "\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "print(best_params)\n",
        "\n",
        "print(f'Best score: {grid_result.best_score_}')"
      ],
      "metadata": {
        "id": "RwlQcshaGcLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35dbde7-aba9-460b-8255-5fd95671c4ff"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 105\n",
            "max_resources_: 2851\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 32\n",
            "n_resources: 105\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 11\n",
            "n_resources: 315\n",
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 4\n",
            "n_resources: 945\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 2835\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "{'classifier__activation': 'tanh', 'classifier__alpha': 0.0001, 'classifier__hidden_layer_sizes': (20,), 'classifier__learning_rate': 'adaptive', 'classifier__solver': 'adam'}\n",
            "Best score: 0.27716381639145576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}