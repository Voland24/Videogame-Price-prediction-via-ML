{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a692e276-6f0d-4bff-9102-2214a6d4b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 32\n",
      "max_resources_: 2664\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 81\n",
      "n_resources: 32\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 96\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 9\n",
      "n_resources: 288\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 864\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 1\n",
      "n_resources: 2592\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best parameters: {'classifier__colsample_bytree': 0.3, 'classifier__gamma': 0, 'classifier__lambda': 1, 'classifier__learning_rate': 0.005, 'classifier__max_depth': 3, 'classifier__n_estimators': 1000}\n",
      "Best accuracy:  0.6395111697599114\n",
      "Score 0.6274433838880681\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classification - halvinggridsearch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_json('./content/video_games_newer_all_data_with_rawg_final_for_train_v2.json')\n",
    "data = data[data.NA_Sales <= 6]\n",
    "data = data[data.EU_Sales <= 2]\n",
    "data = data[data.JP_Sales <= 0.7]\n",
    "data = data[data.Other_Sales <= 2]\n",
    "data = data[data.Global_Sales <= 6]\n",
    "data = data.drop(columns = ['Year_of_Release','Global_Sales'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data['User_Score'] = np.where(data['User_Score'] < 7.5, 0, data['User_Score'])\n",
    "data['User_Score'] = np.where(7.5 <= data['User_Score'] , 1, data['User_Score'])\n",
    "\n",
    "training, test = train_test_split(data, test_size = 0.25, random_state = 32)\n",
    "\n",
    "features = training.drop(['User_Score'], axis = 1).columns\n",
    "\n",
    "training_features, training_labels = training[features], training['User_Score']\n",
    "training[['added', 'screenshots_count', \n",
    "     'achievements_count',    'reddit_count',    'twitch_count',    'youtube_count',\n",
    "     'ratings_count',    'suggestions_count',    'additions_count',\n",
    "     'game_series_count',    'reviews_count','NA_Sales','EU_Sales','JP_Sales','Other_Sales']] = scaler.fit_transform(training[['added', 'screenshots_count', \n",
    "     'achievements_count',    'reddit_count',    'twitch_count',    'youtube_count',\n",
    "     'ratings_count',    'suggestions_count',    'additions_count',\n",
    "     'game_series_count',    'reviews_count','NA_Sales','EU_Sales','JP_Sales','Other_Sales']])\n",
    "test_features, test_labels = test[features], test['User_Score']\n",
    "test[['added', 'screenshots_count', \n",
    "     'achievements_count',    'reddit_count',    'twitch_count',    'youtube_count',\n",
    "     'ratings_count',    'suggestions_count',    'additions_count',\n",
    "     'game_series_count',    'reviews_count','NA_Sales','EU_Sales','JP_Sales','Other_Sales']] = scaler.transform(test[['added', 'screenshots_count', \n",
    "     'achievements_count',    'reddit_count',    'twitch_count',    'youtube_count',\n",
    "     'ratings_count',    'suggestions_count',    'additions_count',\n",
    "     'game_series_count',    'reviews_count','NA_Sales','EU_Sales','JP_Sales','Other_Sales']])\n",
    "\n",
    "params = { \n",
    "    'classifier__max_depth': [3,6,10],\n",
    "    'classifier__learning_rate': [0.001, 0.005, 0.01],\n",
    "    'classifier__n_estimators': [100, 500, 1000],\n",
    "    'classifier__colsample_bytree': [0.1, 0.3, 0.7],\n",
    "    'classifier__lambda': [1],\n",
    "    'classifier__gamma': [0]\n",
    "}\n",
    "\n",
    "xgb_pipeline = Pipeline([('classifier', XGBClassifier())])\n",
    "clf = HalvingGridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=params,               \n",
    "    scoring='f1_macro', \n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(training_features, training_labels)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Best accuracy: \", clf.best_score_)\n",
    "f1_macro = clf.score(test_features, test_labels)\n",
    "print(f'Score {f1_macro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd8acf-05e9-4af6-9ee3-25659754f2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
