{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhFrtnskFq1e9HI7cnqAsj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voland24/Videogame-Price-prediction-via-ML/blob/main/YouTubeCommentsSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOpNUjLJxudD",
        "outputId": "cbd0583a-008d-4bb3-80ae-e9b838151f29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ycFShDq8Hn",
        "outputId": "da2423c1-a4f0-44d3-dae0-d1527fcd8c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The memories.....I NEED A TIME MACHINE NOW\n",
            "12 years later and I still have my Wii! Got it in 2008.\n",
            "I love this game! Man this takes me back.<br>Ahh Memories! 😍\n",
            "I&#39;ve had my Wii since 2008. Still works like a charm in 2020!\n",
            "Don&#39;t we just love the good old days.... I CRY WHEN I FLASHBACK TO THEM!\n",
            "Oh my gosh my childhood\n",
            "I still play Wii Sports with my dad to this very day. We get very competitive in tennis XD\n",
            "Thought it was highest tech at that time... now its still classic and nothing can replace it\n",
            "We’ve come so far since the first ever game in the series! Who’s here in the Nintendo Switch Sports era?\n",
            "this actually looks more hyped up then in the nintendo switch one\n",
            "I&#39;m glad to see this being brought back, but for the switch, regardless, I Can&#39;t wait! :D\n",
            "Que nostalgia\n",
            "I want a switch version of this game! make it happen Nintendo!!!\n",
            "Wii Sports is my favourite game of all time, I remember beating all 3 champions in the OG.\n",
            "I can&#39;t stop playing Wii sports!! I finish Zelda, I finish many other games... and I still playing Wii Sports, specially.... when my friends came to home (most of them were non gamers, and they became to be with Wii lol!!) HAVE FUN!!\n",
            "Wii is the best and so fun and active even healthy I really want it\n",
            "One of my favorite Wii games.\n",
            "Remember getting this on launch 😎\n",
            "The tv graphics geez classic\n",
            "I remember watching my sisters play this back when I was 4 in 2011\n",
            "The nostalgia is making me tear up\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient.discovery import build\n",
        "video_id = \"zqaPFAZS1K8\"\n",
        "api_key = 'AIzaSyBxEn9yCwwIIjKrW785e5--IlyWBebpHBM'\n",
        "\n",
        "# recursive function to get all replies in a comment thread\n",
        "def get_replies(comment_id, token):\n",
        "    replies_response = yt_object.comments().list(part = 'snippet', maxResults = 10, parentId = comment_id, pageToken = token).execute()\n",
        "\n",
        "    for reply in replies_response['items']:\n",
        "        all_comments.append(reply['snippet']['textDisplay'])\n",
        "\n",
        "    if replies_response.get(\"nextPageToken\"):\n",
        "        return get_replies(comment_id, replies_response['nextPageToken'])\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "\n",
        "# recursive function to get all comments\n",
        "def get_comments(youtube, video_id, next_view_token):\n",
        "    global all_comments\n",
        "\n",
        "    # check for token\n",
        "    if len(next_view_token.strip()) == 0:\n",
        "        all_comments = []\n",
        "\n",
        "    if next_view_token == '':\n",
        "        # get the initial response\n",
        "        comment_list = youtube.commentThreads().list(part = 'snippet', maxResults = 10, videoId = video_id, order = 'relevance').execute()\n",
        "    else:\n",
        "        # get the next page response\n",
        "        comment_list = youtube.commentThreads().list(part = 'snippet', maxResults = 10, videoId = video_id, order='relevance', pageToken=next_view_token).execute()\n",
        "    # loop through all top level comments\n",
        "    for comment in comment_list['items']:\n",
        "        # add comment to list\n",
        "        all_comments.append([comment['snippet']['topLevelComment']['snippet']['textDisplay']])\n",
        "        # get number of replies\n",
        "        reply_count = comment['snippet']['totalReplyCount']\n",
        "        all_replies = []\n",
        "        # # if replies greater than 0\n",
        "        # if reply_count > 0:\n",
        "        #     # get first 100 replies\n",
        "        #     replies_list = youtube.comments().list(part='snippet', maxResults=10, parentId=comment['id']).execute()\n",
        "        #     for reply in replies_list['items']:\n",
        "        #         # add reply to list\n",
        "        #         all_replies.append(reply['snippet']['textDisplay'])\n",
        "\n",
        "        #     # check for more replies\n",
        "        #     while \"nextPageToken\" in replies_list:\n",
        "        #         token_reply = replies_list['nextPageToken']\n",
        "        #         # get next set of 100 replies\n",
        "        #         replies_list = youtube.comments().list(part = 'snippet', maxResults = 10, parentId = comment['id'], pageToken = token_reply).execute()\n",
        "        #         for reply in replies_list['items']:\n",
        "        #             # add reply to list\n",
        "        #             all_replies.append(reply['snippet']['textDisplay'])\n",
        "\n",
        "        # add all replies to the comment\n",
        "        all_comments[-1].append(all_replies)\n",
        "\n",
        "    if \"nextPageToken\" in comment_list:\n",
        "        return get_comments(youtube, video_id, comment_list['nextPageToken'])\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "  # build a youtube object using our api key\n",
        "yt_object = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "  # get all comments and replies\n",
        "get_comments(yt_object, video_id, '')\n",
        "\n",
        "for i, comm in enumerate(all_comments):\n",
        "  print(comm[0])\n",
        "  if i == 20:\n",
        "    break\n",
        "\n",
        "# for comment, replies in all_comments:\n",
        "#     print(comment)\n",
        "#     # if len(replies) > 0:\n",
        "#     #     print(\"There are\", len(replies), \"replies\")\n",
        "#     #     print(\"\\tReplies:\")\n",
        "#     #     for reply in replies:\n",
        "#     #         print(\"\\t\" + reply)\n",
        "#     print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "data = [all_comments[20][0]]\n",
        "print(data)\n",
        "sentiment_pipeline(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmgQwePYx7Wb",
        "outputId": "22218c44-7bc1-402c-c5f9-011b20193830"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The nostalgia is making me tear up']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9980940222740173}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "video_id = 'zqaPFAZS1K8'\n",
        "key = 'AIzaSyBxEn9yCwwIIjKrW785e5--IlyWBebpHBM'\n",
        "\n",
        "url = (f'https://www.googleapis.com/youtube/v3/videos?id={video_id}&key={key}&part=statistics ')\n",
        "response = requests.get(url)\n",
        "payload = response.json()\n"
      ],
      "metadata": {
        "id": "wWYzW9eV1MqT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(payload['items'][0]['statistics'])"
      ],
      "metadata": {
        "id": "Qe2GZrI9j4Pk",
        "outputId": "0bb48fef-02bf-428f-e08e-cb57b45be9f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'viewCount': '1330883', 'likeCount': '2610', 'favoriteCount': '0', 'commentCount': '462'}\n"
          ]
        }
      ]
    }
  ]
}